redis_version:4.0.2

HAProxy version 1.5.18

kafka_2.12-1.0.0

zeppelin-0.7.3-bin-all


zookeeper-3.4.10

jdk-8u152-linux-x64

spark 2.2.0

hbase 1.2.6

zookeeper(hadoop)3.4.6

hadoop 2.7.3oenixxx


하둡(Hadoop) 완전분산, 네임노드 HA구성

1. 프로그램 설치정보
> Hadoop hadoop-2.7.3
 > JAVA java 1.8.0_11
 > 주키퍼 설치

2. 하둡 설치 내용
> name01 : Zookeeper,journalnode,master namenode,resourcemanager
 > name02 : Zookeeper,journalnode,standby namenode
 > data01 : Zookeeper,journalnode,datanode,nodemanager 
 > data02 : datanode,nodemanager 
 > data03 : datanode,nodemanager 

3. 하둡 계정 
> 계정생성
groupadd -g 500 hadoop
 useradd -u 500 -g 500 -G wheel -d /home/hadoop hadoop
 echo 'Tkdldnjfem' | passwd --stdin hadoop

> SSH설정 
ssh-keygen -t rsa /* 모든서버 */
ssh-copy-id hadoop@10.6.0.14 
 scp hadoop@10.6.0.14:/home/hadoop/.ssh/authorized_keys /home/hadoop/.ssh/

4. /etc/hosts 추가
10.6.0.14 name01
 10.6.0.15 name02
 10.6.0.17 data01
 10.6.0.18 data02
 10.6.0.19 data03

5. JAVA 설치
> JAVA_HOME=/usr/java/jdk
 mkdir -p /usr/java
 cd /usr/java
 tar xvfz jdk-8u11-linux-x64.tar.gz
 ln -s usr/java/jdk1.8.0_11 jdk

vi /etc/profile 내용추가
export JAVA_HOME=/usr/java/jdk
 export JRE_HOME=/usr/java/jdk/jre
 export CLASSPATH=$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar:.
 export PATH=$JAVA_HOME/bin:$PATH

resource /etc/profile
 java -version

6. 프로토콜 버퍼 설치(Protocol Buffer) , root계정
cd /usr/local /* 설치디렉토리 */
wget https://github.com/google/protobuf/releases/download/v2.6.0/protobuf-2.6.0.tar.gz
 tar xvfz protobuf-2.6.0.tar.gz
 cd protobuf-2.6.0
 ./configure
 make
 make install

7. 주키퍼 설치
> 계정생성
groupadd -g 502 zookeeper
 useradd -u 502 -g 502 -d /home/zookeeper zookeeper
 echo 'Tkdldnjfem' | passwd --stdin zookeeper

> SSH설정
su - zookeeper
 ssh-keygen -t rsa /* 모든서버 */
ssh-copy-id zookeeper@10.6.0.14 
 scp zookeeper@10.6.0.14:/home/zookeeper/.ssh/authorized_keys /home/zookeeper/.ssh/

> 다운로드.설치.설정 
cd /home/zookeeper/
 wget "http://apache.tt.co.kr/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz"
 tar xvfz zookeeper-3.4.10.tar.gz

mkdir /home/zookeeper/zookeeper-3.4.10/data
 cd /home/zookeeper/zookeeper-3.4.10/conf
 cp -a zoo_sample.cfg zoo.cfg

echo
 '# The number of milliseconds of each tick
 tickTime=2000
1.The number of ticks that the initial
2.synchronization phase can take
 initLimit=10
3.The number of ticks that can pass between
4.sending a request and getting an acknowledgement
 syncLimit=5
5.the directory where the snapshot is stored.
6.do not use /tmp for storage, /tmp here is just
7.example sakes.
 #dataDir=/tmp/zookeeper
 dataDir=/home/zookeeper/zookeeper-3.4.10/data
8.the port at which the clients will connect
 clientPort=2181
9.the maximum number of client connections.
10.increase this if you need to handle more clients
 #maxClientCnxns=60
 maxClientCnxns=0
 #
11.Be sure to read the maintenance section of the
12.administrator guide before turning on autopurge.
 #
13.http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
 #
14.The number of snapshots to retain in dataDir
 autopurge.snapRetainCount=3
15.Purge task interval in hours
16.Set to "0" to disable auto purge feature
 autopurge.purgeInterval=1

server.1=10.6.0.14:2888:3888
 server.2=10.6.0.15:2888:3888
 server.3=10.6.0.17:2888:3888
 ' > /home/zookeeper/zookeeper-3.4.10/conf/zoo.cfg

> myid 파일생성
cd /home/zookeeper/zookeeper-3.4.10/data
 vi myid
 1

> 주키퍼 실행, 상태 확인
/home/zookeeper/zookeeper-3.4.10/bin/zkServer.sh start
 /home/zookeeper/zookeeper-3.4.10/bin/zkServer.sh stop
 /home/zookeeper/zookeeper-3.4.10/bin/zkServer.sh status

8. 하둡설치
1) 하둡다운로드.압축해제
cd /home/hadoop
 wget "http://mirror.apache-kr.org/hadoop/common/stable2/hadoop-2.7.3.tar.gz"
 tar xvfz hadoop-2.7.3.tar.gz
 ln -s hadoop-2.7.3 hadoop2

2) 하둡 환경설정
vi .bashrc /* 내용추가 */
export HADOOP_HOME=/home/hadoop/hadoop2
 export JAVA_HOME=/usr/java/jdk

. .bashrc

3) 하둡 디렉토리 생성
> dfs.namenode.name.dir
 mkdir -p /data1/dfs/namenode 

> dfs.datanode.data.dir
 mkdir -p /data1/dfs/datanode

> dfs.journalnode.edits.dir
 mkdir -p /data1/dfs/journalnode

> yarn.nodemanager.local-dir
 mkdir -p /data1/yarn/nm-local-dir

>yarn.resourcemanager.fs.state-store.uri
 mkdir -p /data1/yarn/system/rmstore

> 정리...
mkdir -p /data1/dfs/namenode 
 mkdir -p /data1/dfs/datanode
 mkdir -p /data1/dfs/journalnode
 mkdir -p /data1/yarn/nm-local-dir
 mkdir -p /data1/yarn/system/rmstore
 chwon -R hadoop.hadoop /data1

4) 설정 수정 
> Configuration 수정
vi /home/hadoop/hadoop-2.7.3/etc/hadoop/hadoop-env.sh
 vi /home/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml
 vi /home/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml
 vi /home/hadoop/hadoop-2.7.3/etc/hadoop/mapred-site.xml
 vi /home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-site.xml
 vi /home/hadoop/hadoop-2.7.3/etc/hadoop/slaves
 vi /home/hadoop/hadoop-2.7.3/etc/hadoop/masters /* HA 사용안함*/

> 설정파일 배포
scp /home/hadoop/hadoop-2.7.3/etc/hadoop/hadoop-env.sh name02:/home/hadoop/hadoop-2.7.3/etc/hadoop/hadoop-env.sh
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/hadoop-env.sh data01:/home/hadoop/hadoop-2.7.3/etc/hadoop/hadoop-env.sh 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/hadoop-env.sh data02:/home/hadoop/hadoop-2.7.3/etc/hadoop/hadoop-env.sh 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/hadoop-env.sh data03:/home/hadoop/hadoop-2.7.3/etc/hadoop/hadoop-env.sh 

scp /home/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml name02:/home/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml data01:/home/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml data02:/home/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml data03:/home/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml 

scp /home/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml name02:/home/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml data01:/home/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml data02:/home/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml data03:/home/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml 

scp /home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-env.sh name02:/home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-env.sh
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-env.sh data01:/home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-env.sh 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-env.sh data02:/home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-env.sh 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-env.sh data03:/home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-env.sh 

scp /home/hadoop/hadoop-2.7.3/etc/hadoop/mapred-site.xml name02:/home/hadoop/hadoop-2.7.3/etc/hadoop/mapred-site.xml
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/mapred-site.xml data01:/home/hadoop/hadoop-2.7.3/etc/hadoop/mapred-site.xml 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/mapred-site.xml data02:/home/hadoop/hadoop-2.7.3/etc/hadoop/mapred-site.xml 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/mapred-site.xml data03:/home/hadoop/hadoop-2.7.3/etc/hadoop/mapred-site.xml 

scp /home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-site.xml name02:/home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-site.xml 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-site.xml data01:/home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-site.xml 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-site.xml data02:/home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-site.xml 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-site.xml data03:/home/hadoop/hadoop-2.7.3/etc/hadoop/yarn-site.xml 

scp /home/hadoop/hadoop-2.7.3/etc/hadoop/slaves name02:/home/hadoop/hadoop-2.7.3/etc/hadoop/slaves 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/slaves data01:/home/hadoop/hadoop-2.7.3/etc/hadoop/slaves 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/slaves data02:/home/hadoop/hadoop-2.7.3/etc/hadoop/slaves 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/slaves data03:/home/hadoop/hadoop-2.7.3/etc/hadoop/slaves 

scp /home/hadoop/hadoop-2.7.3/etc/hadoop/masters name02:/home/hadoop/hadoop-2.7.3/etc/hadoop/masters 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/masters data01:/home/hadoop/hadoop-2.7.3/etc/hadoop/masters 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/masters data02:/home/hadoop/hadoop-2.7.3/etc/hadoop/masters 
 scp /home/hadoop/hadoop-2.7.3/etc/hadoop/masters data03:/home/hadoop/hadoop-2.7.3/etc/hadoop/masters 

9. 하둡 초기화, 실행 방법
1) 주키퍼 초기화
/home/hadoop/hadoop-2.7.3/bin/hdfs zkfc -formatZK

2) NameNode 포맷
> 저널노드 실행... HA에서는 NameNode 포맷하기전에 실행 되어야 한다.
 /home/hadoop/hadoop-2.7.3/sbin/hadoop-daemon.sh start journalnode
 /home/hadoop/hadoop-2.7.3/sbin/hadoop-daemon.sh stop journalnode
 > 네임노드 포맷
/home/hadoop/hadoop-2.7.3/bin/hdfs namenode -format

3) NameNode 실행 (액티브 NameNode)
 /home/hadoop/hadoop-2.7.3/sbin/hadoop-daemon.sh start namenode
 /home/hadoop/hadoop-2.7.3/sbin/hadoop-daemon.sh stop namenode

4) NameNode 주키퍼 장애 컨트롤러 실행(액티브 NameNode)
 /home/hadoop/hadoop-2.7.3/sbin/hadoop-daemon.sh start zkfc
 /home/hadoop/hadoop-2.7.3sbin/hadoop-daemon.sh stop zkfc

5) DataNode 실행
/home/hadoop/hadoop-2.7.3/sbin/hadoop-daemon.sh start datanode
 /home/hadoop/hadoop-2.7.3/sbin/hadoop-daemon.sh stop datanode

/home/hadoop/hadoop-2.7.3/sbin/yarn-daemon.sh start nodemanager
 /home/hadoop/hadoop-2.7.3/sbin/yarn-daemon.sh stop nodemanager

6) Standby NameNode
 > 액티브네임노드 메타데이터 복사... 
 /home/hadoop/hadoop-2.7.3/bin/hdfs namenode -bootstrapStandby

> Standby NameNode 실행
/home/hadoop/hadoop-2.7.3/sbin/hadoop-daemon.sh start namenode
 /home/hadoop/hadoop-2.7.3/sbin/hadoop-daemon.sh stop namenode

> standby 주키퍼 장애 컨트롤러 실행 
/home/hadoop/hadoop-2.7.3/sbin/hadoop-daemon.sh start zkfc
 /home/hadoop/hadoop-2.7.3sbin/hadoop-daemon.sh stop zkfc

10. HDFS 설치 완료
> HDFS 상태 확인
/home/hadoop/hadoop-2.7.3/bin/hadoop dfsadmin -report

...테스트

> 
 /home/hadoop/hadoop-2.7.3/bin/hdfs dfs -mkdir temp
 /home/hadoop/hadoop-2.7.3/bin/hdfs dfs -mkdir temp/hadoop
 /home/hadoop/hadoop-2.7.3/bin/hdfs dfs -mkdir temp/hadoop/conf
 /home/hadoop/hadoop-2.7.3/bin/hdfs dfs -put /home/hadoop/hadoop-2.7.3/etc/hadoop-env.sh temp/hadoop/conf/
 home/hadoop/hadoop-2.7.3/bin/hdfs dfs -ls temp/hadoop/conf

11. 얀, 맴리듀스, 히스토리 서버 실행

1) 얀... Resource Manager
 /home/hadoop/hadoop-2.7.3/sbin/start-yarn.sh

2) 맴리듀스 historyserver
 /home/hadoop/hadoop-2.7.3/sbin/mr-jobhistory-daemon.sh start historyserver

3) Proxyserver
 /home/hadoop/hadoop-2.7.3/sbin/yarn-daemon.sh start proxyserver

12. 로그 경로
tail -f /home/hadoop/ha사oop-2.7.3/logs/hadoop-hadoop-datanode-data01.log
 tail -f /home/hadoop/hadoop-2.7.3/logs/hadoop-hadoop-datanode-data02.log
 tail -f /home/hadoop/hadoop-2.7.3/logs/hadoop-hadoop-datanode-data03.log

13. 관리페이지
http://10.6.0.14:50070/

13. 주요참고 사이트...
http://excelsior-cjh.tistory.com/entry/Hadoop2%ED%95%98%EB%91%A12%EC%84%A4%EC%B9%98-%EC%99%84%EC%A0%84%EB%B6%84%EC%82%B0%EB%AA%A8%EB%93%9C-%EB%84%A4%EC%9E%84%EB%85%B8%EB%93%9C-HA%EA%B5%AC%EC%84%B1
https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html

설치 참고
http://blog.naver.com/PostView.nhn?blogId=8x8x8x8x8x8&logNo=220685439665
http://opennote46.tistory.com/121
http://blog.iotinfra.net/?p=1275

다운로드 URL
https://archive.apache.org/dist/hadoop/common/
